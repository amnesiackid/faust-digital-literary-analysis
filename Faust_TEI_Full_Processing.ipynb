{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbe14d4e",
   "metadata": {},
   "source": [
    "# Faust TEI Full Processing\n",
    "Structural extraction, TEI enhancement, word frequency statistics, character co-occurrence network analysis, visualization, and Neo4j export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3391da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "xml_files = {\n",
    "    \"Faust_I\": \"/Users/lisiqi/Documents/Text_Tech/faust_project/data/Faust._Der_Tragoedie_erster_Teil.11g9p.0.xml\",\n",
    "    \"Faust_II\": \"/Users/lisiqi/Documents/Text_Tech/faust_project/data/Faust._Der_Tragoedie_zweiter_Teil.11d12.0.xml\"\n",
    "}\n",
    "\n",
    "ns = {'tei': \"http://www.tei-c.org/ns/1.0\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87343c50",
   "metadata": {},
   "source": [
    "## TEI Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaa4476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse an XML file and return the parsed tree\n",
    "def parse_xml(file_path):\n",
    "    return etree.parse(file_path)\n",
    "\n",
    "# Extract all scene headers (excluding acts and front matter)\n",
    "def extract_scenes(tree):\n",
    "    scenes = tree.xpath(\"//tei:div[not(@type='act') and not(@type='front') and tei:head]/tei:head/text()\", namespaces=ns)\n",
    "    return [scene.strip() for scene in scenes if scene.strip()]\n",
    "\n",
    "# Extract and return unique speakers sorted alphabetically\n",
    "def extract_speakers(tree):\n",
    "    speakers = tree.xpath(\"//tei:sp/tei:speaker/text()\", namespaces=ns)\n",
    "    speaker_names = {speaker.strip() for speaker in speakers if speaker.strip()}\n",
    "    return sorted(speaker_names)\n",
    "\n",
    "# Extract all poetic lines\n",
    "def extract_lines(tree):\n",
    "    lines = tree.xpath(\"//tei:l\", namespaces=ns)\n",
    "    lines_text = [''.join(line.itertext()).strip() for line in lines if ''.join(line.itertext()).strip()]\n",
    "    return lines_text\n",
    "\n",
    "# Extract the last word from each poetic line (rhyme word)\n",
    "def extract_rhyme_words(lines_text):\n",
    "    last_words = []\n",
    "    for line in lines_text:\n",
    "        tokens = line.split()\n",
    "        while tokens:\n",
    "            tok = tokens.pop()\n",
    "            word = tok.strip('.,;:!?…–—-\"\\'()[]')\n",
    "            if word:\n",
    "                last_words.append(word)\n",
    "                break\n",
    "        else:\n",
    "            last_words.append(\"\")\n",
    "    return [word for word in last_words if word]\n",
    "\n",
    "# Get the last few characters from a word for rhyme comparison\n",
    "def get_rhyme_part(word, length=3):\n",
    "    return word[-length:].lower()\n",
    "\n",
    "# Enhance the TEI XML by adding attributes to each scene\n",
    "def enhance_tei(tree, xml_path):\n",
    "    for scene in tree.xpath(\"//tei:div[@type='h4']\", namespaces=ns):\n",
    "        # Extract rhyme-ending words from poetic lines\n",
    "        rhyme_ends = []\n",
    "        for l in scene.xpath(\".//tei:l\", namespaces=ns):\n",
    "            text = \"\".join(l.itertext()).strip() if l.text is None else l.text.strip()\n",
    "            if text:\n",
    "                last_word = text.split()[-1].strip('.,;:!?…–—-\"\\'()[]')\n",
    "                rhyme_ends.append(last_word)\n",
    "        scene.attrib['rhyme_ends'] = \",\".join(rhyme_ends[:20])  # Save first 20 rhyme endings\n",
    "\n",
    "        # Extract unique speakers and their frequency\n",
    "        speakers = [sp.text.strip() for sp in scene.xpath(\".//tei:sp/tei:speaker\", namespaces=ns) if sp.text]\n",
    "        unique_speakers = sorted(set(speakers))\n",
    "        scene.attrib['speakers_unique'] = \",\".join(unique_speakers)\n",
    "        scene.attrib['speakers_count'] = str(len(unique_speakers))\n",
    "        freq = Counter(speakers)\n",
    "        freq_str = \";\".join(f\"{name}:{freq[name]}\" for name in unique_speakers)\n",
    "        scene.attrib['speaker_freq'] = freq_str\n",
    "\n",
    "    # Save the enhanced XML file\n",
    "    enhanced_path = os.path.splitext(xml_path)[0] + \"_enhanced.xml\"\n",
    "    tree.write(enhanced_path, encoding=\"utf-8\", xml_declaration=True, pretty_print=True)\n",
    "    print(f\"Enhanced XML saved: {enhanced_path}\")\n",
    "    return enhanced_path\n",
    "\n",
    "# Normalize and clean speaker names\n",
    "def clean_name(name):\n",
    "    return name.strip().strip('.,;:!?…–—-\"\\'()[]').title()\n",
    "\n",
    "# Analyze word frequencies and character co-occurrences, generate plots and Neo4j CSVs\n",
    "def analyze_network(xml_path, title):\n",
    "    tree = etree.parse(xml_path)\n",
    "    scene_wordfreq = {}\n",
    "    total_wordfreq = Counter()\n",
    "    scene_character_links = []\n",
    "    cooccur_counts = defaultdict(int)\n",
    "\n",
    "    # Iterate through all scenes\n",
    "    for scene in tree.xpath(\"//tei:div[@type='h4']\", namespaces=ns):\n",
    "        head = scene.find(\"tei:head\", namespaces=ns)\n",
    "        scene_name = head.text.strip() if head is not None else \"Unnamed\"\n",
    "        words = []\n",
    "\n",
    "        # Collect words from all poetic lines\n",
    "        for l in scene.xpath(\".//tei:l\", namespaces=ns):\n",
    "            line_text = \"\".join(l.itertext()).strip()\n",
    "            for word in line_text.split():\n",
    "                clean = word.strip('.,;:!?…–—-\"\\'()[]')\n",
    "                if clean: words.append(clean.lower())\n",
    "        wc = Counter(words)\n",
    "        scene_wordfreq[scene_name] = wc\n",
    "        total_wordfreq.update(words)\n",
    "\n",
    "        # Collect speaker data for this scene\n",
    "        scene_full_name = f\"{title}::{scene_name}\"\n",
    "        speakers = [clean_name(sp.text) for sp in scene.xpath(\".//tei:sp/tei:speaker\", namespaces=ns) if sp.text]\n",
    "        for speaker in set(speakers):\n",
    "            scene_character_links.append({\"play\": title, \"scene\": scene_full_name, \"character\": speaker})\n",
    "\n",
    "        # Count co-occurrences between every pair of speakers\n",
    "        unique_speakers = sorted(set(speakers))\n",
    "        for a, b in itertools.combinations(unique_speakers, 2):\n",
    "            key = tuple(sorted([a, b]))\n",
    "            cooccur_counts[key] += 1\n",
    "\n",
    "    # Save word frequencies to CSV\n",
    "    pd.DataFrame({\"word\": list(total_wordfreq.keys()), \"freq\": list(total_wordfreq.values())}).to_csv(f\"{title.lower()}_total_wordfreq.csv\", index=False)\n",
    "    print(f\"{title} word frequency saved: {title.lower()}_total_wordfreq.csv\")\n",
    "\n",
    "    # Save scene-character table\n",
    "    pd.DataFrame(scene_character_links).to_csv(f\"{title.lower()}_scene_character.csv\", index=False)\n",
    "    print(f\"{title} scene-character table saved: {title.lower()}_scene_character.csv\")\n",
    "\n",
    "    # Save character co-occurrence edge list\n",
    "    edges = [{\"source\": a, \"target\": b, \"weight\": count} for (a, b), count in cooccur_counts.items()]\n",
    "    pd.DataFrame(edges).to_csv(f\"{title.lower()}_character_cooccurrence.csv\", index=False)\n",
    "    print(f\"{title} character co-occurrence edge list saved: {title.lower()}_character_cooccurrence.csv\")\n",
    "\n",
    "    # Save character node list\n",
    "    all_characters = set(link['character'] for link in scene_character_links)\n",
    "    pd.DataFrame([{\"id\": name, \"label\": \"Character\"} for name in sorted(all_characters)]).to_csv(f\"{title.lower()}_characters_nodes.csv\", index=False)\n",
    "    print(f\"{title} node list saved: {title.lower()}_characters_nodes.csv\")\n",
    "\n",
    "    G = nx.Graph()\n",
    "    for edge in edges:\n",
    "        G.add_edge(edge[\"source\"], edge[\"target\"], weight=edge[\"weight\"])\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "    weights = [G[u][v]['weight'] for u, v in G.edges()]\n",
    "    nx.draw_networkx(G, pos, with_labels=True, width=weights, node_size=800, font_size=10)\n",
    "    plt.title(f\"{title} Character Co-occurrence Network\")\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f\"{title.lower()}_network_plot.png\")\n",
    "    plt.show()\n",
    "\n",
    "    # Export Neo4j-compatible CSV files\n",
    "    pd.DataFrame({\"name\": list(all_characters), \"label\": [\"Character\"] * len(all_characters)}).to_csv(f\"{title.lower()}_neo4j_nodes.csv\", index=False)\n",
    "    pd.DataFrame(edges).to_csv(f\"{title.lower()}_neo4j_edges.csv\", index=False)\n",
    "    print(f\"{title} Neo4j CSV files saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d82c8f",
   "metadata": {},
   "source": [
    "## Character Networks and Rhyme Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d700fc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store extracted results\n",
    "analysis_results = {}\n",
    "\n",
    "# Process each XML file\n",
    "for title, path in xml_files.items():\n",
    "    print(f\"\\nProcessing: {title}\")\n",
    "    tree = parse_xml(path)\n",
    "\n",
    "    # Extract core elements from the XML\n",
    "    scenes = extract_scenes(tree)\n",
    "    speakers = extract_speakers(tree)\n",
    "    lines_text = extract_lines(tree)\n",
    "    rhyme_words = extract_rhyme_words(lines_text)\n",
    "    rhyme_parts = [get_rhyme_part(word) for word in rhyme_words]\n",
    "\n",
    "    # Save extracted data into a dictionary\n",
    "    analysis_results[title] = {\n",
    "        \"scenes\": scenes,\n",
    "        \"speakers\": speakers,\n",
    "        \"lines_text\": lines_text,\n",
    "        \"rhyme_parts\": rhyme_parts\n",
    "    }\n",
    "\n",
    "    print(f\"- Scenes ({len(scenes)}): {scenes[:5]}\")\n",
    "    print(f\"- Unique Speakers ({len(speakers)}): {speakers[:5]}\")\n",
    "    print(f\"- Total Lines: {len(lines_text)}\")\n",
    "    print(f\"- Sample Rhyme parts: {rhyme_parts[:5]}\")\n",
    "\n",
    "    # Enhance the XML and analyze network\n",
    "    enhanced_xml_path = enhance_tei(tree, path)\n",
    "    analyze_network(enhanced_xml_path, title)\n",
    "\n",
    "# Save the structured data to JSON\n",
    "with open(\"faust_struct_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(analysis_results, f, ensure_ascii=False, indent=2)\n",
    "print(\"Structured data saved: faust_struct_data.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
